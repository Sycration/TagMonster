/*
 * Box Platform API
 *
 * [Box Platform](https://box.dev) provides functionality to provide access to content stored within [Box](https://box.com). It provides endpoints for basic manipulation of files and folders, management of users within an enterprise, as well as more complex topics such as legal holds and retention policies.
 *
 * The version of the OpenAPI document: 2024.0
 * Contact: devrel@box.com
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// AiLlmEndpointParamsOpenAi : AI LLM endpoint params OpenAI object.
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct AiLlmEndpointParamsOpenAi {
    /// The type of the AI LLM endpoint params object for OpenAI. This parameter is **required**.
    #[serde(rename = "type")]
    pub r#type: Type,
    /// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random,  while lower values like 0.2 will make it more focused and deterministic.  We generally recommend altering this or `top_p` but not both.
    #[serde(rename = "temperature", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub temperature: Option<Option<f64>>,
    /// An alternative to sampling with temperature, called nucleus sampling, where the model considers the results  of the tokens with `top_p` probability mass. So 0.1 means only the tokens comprising the top 10% probability  mass are considered. We generally recommend altering this or temperature but not both.
    #[serde(rename = "top_p", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub top_p: Option<Option<f64>>,
    /// A number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the  text so far, decreasing the model's likelihood to repeat the same line verbatim.
    #[serde(rename = "frequency_penalty", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub frequency_penalty: Option<Option<f64>>,
    /// A number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
    #[serde(rename = "presence_penalty", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub presence_penalty: Option<Option<f64>>,
    /// Up to 4 sequences where the API will stop generating further tokens.
    #[serde(rename = "stop", default, with = "::serde_with::rust::double_option", skip_serializing_if = "Option::is_none")]
    pub stop: Option<Option<String>>,
}

impl AiLlmEndpointParamsOpenAi {
    /// AI LLM endpoint params OpenAI object.
    pub fn new(r#type: Type) -> AiLlmEndpointParamsOpenAi {
        AiLlmEndpointParamsOpenAi {
            r#type,
            temperature: None,
            top_p: None,
            frequency_penalty: None,
            presence_penalty: None,
            stop: None,
        }
    }
}
/// The type of the AI LLM endpoint params object for OpenAI. This parameter is **required**.
#[derive(Clone, Copy, Debug, Eq, PartialEq, Ord, PartialOrd, Hash, Serialize, Deserialize)]
pub enum Type {
    #[serde(rename = "openai_params")]
    OpenaiParams,
}

impl Default for Type {
    fn default() -> Type {
        Self::OpenaiParams
    }
}

