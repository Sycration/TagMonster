/*
 * Box Platform API
 *
 * [Box Platform](https://box.dev) provides functionality to provide access to content stored within [Box](https://box.com). It provides endpoints for basic manipulation of files and folders, management of users within an enterprise, as well as more complex topics such as legal holds and retention policies.
 *
 * The version of the OpenAPI document: 2024.0
 * Contact: devrel@box.com
 * Generated by: https://openapi-generator.tech
 */

use crate::models;
use serde::{Deserialize, Serialize};

/// AiAgentBasicTextTool : AI agent processor used to handle basic text.
#[derive(Clone, Default, Debug, PartialEq, Serialize, Deserialize)]
pub struct AiAgentBasicTextTool {
    /// The model used for the AI agent for basic text. For specific model values, see the [available models list](g://box-ai/supported-models).
    #[serde(rename = "model", skip_serializing_if = "Option::is_none")]
    pub model: Option<String>,
    /// The number of tokens for completion.
    #[serde(rename = "num_tokens_for_completion", skip_serializing_if = "Option::is_none")]
    pub num_tokens_for_completion: Option<i32>,
    #[serde(rename = "llm_endpoint_params", skip_serializing_if = "Option::is_none")]
    pub llm_endpoint_params: Option<Box<models::AiLlmEndpointParams>>,
    /// System messages try to help the LLM \"understand\" its role and what it is supposed to do.
    #[serde(rename = "system_message", skip_serializing_if = "Option::is_none")]
    pub system_message: Option<String>,
    /// The prompt template contains contextual information of the request and the user prompt. When passing `prompt_template` parameters, you **must include** inputs for `{user_question}` and `{content}`. `{current_date}` is optional, depending on the use.
    #[serde(rename = "prompt_template", skip_serializing_if = "Option::is_none")]
    pub prompt_template: Option<String>,
}

impl AiAgentBasicTextTool {
    /// AI agent processor used to handle basic text.
    pub fn new() -> AiAgentBasicTextTool {
        AiAgentBasicTextTool {
            model: None,
            num_tokens_for_completion: None,
            llm_endpoint_params: None,
            system_message: None,
            prompt_template: None,
        }
    }
}

