/*
 * Box Platform API
 *
 * [Box Platform](https://box.dev) provides functionality to provide access to content stored within [Box](https://box.com). It provides endpoints for basic manipulation of files and folders, management of users within an enterprise, as well as more complex topics such as legal holds and retention policies.
 *
 * The version of the OpenAPI document: 2024.0
 * Contact: devrel@box.com
 * Generated by: https://openapi-generator.tech
 */


use reqwest;
use serde::{Deserialize, Serialize, de::Error as _};
use crate::{apis::ResponseContent, models};
use super::{Error, configuration, ContentType};

/// struct for passing parameters to the method [`get_ai_agent_default`]
#[derive(Clone, Debug)]
pub struct GetAiAgentDefaultParams {
    /// The mode to filter the agent config to return.
    pub mode: String,
    /// The ISO language code to return the agent config for. If the language is not supported the default agent config is returned.
    pub language: Option<String>,
    /// The model to return the default agent config for.
    pub model: Option<String>
}

/// struct for passing parameters to the method [`post_ai_ask`]
#[derive(Clone, Debug)]
pub struct PostAiAskParams {
    pub ai_ask: Option<models::AiAsk>
}

/// struct for passing parameters to the method [`post_ai_extract`]
#[derive(Clone, Debug)]
pub struct PostAiExtractParams {
    pub ai_extract: Option<models::AiExtract>
}

/// struct for passing parameters to the method [`post_ai_extract_structured`]
#[derive(Clone, Debug)]
pub struct PostAiExtractStructuredParams {
    pub ai_extract_structured: Option<models::AiExtractStructured>
}

/// struct for passing parameters to the method [`post_ai_text_gen`]
#[derive(Clone, Debug)]
pub struct PostAiTextGenParams {
    pub ai_text_gen: Option<models::AiTextGen>
}


/// struct for typed errors of method [`get_ai_agent_default`]
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum GetAiAgentDefaultError {
    Status500(models::ClientError),
    DefaultResponse(models::ClientError),
    UnknownValue(serde_json::Value),
}

/// struct for typed errors of method [`post_ai_ask`]
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum PostAiAskError {
    Status500(models::ClientError),
    DefaultResponse(models::ClientError),
    UnknownValue(serde_json::Value),
}

/// struct for typed errors of method [`post_ai_extract`]
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum PostAiExtractError {
    Status500(models::ClientError),
    DefaultResponse(models::ClientError),
    UnknownValue(serde_json::Value),
}

/// struct for typed errors of method [`post_ai_extract_structured`]
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum PostAiExtractStructuredError {
    Status500(models::ClientError),
    DefaultResponse(models::ClientError),
    UnknownValue(serde_json::Value),
}

/// struct for typed errors of method [`post_ai_text_gen`]
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(untagged)]
pub enum PostAiTextGenError {
    Status500(models::ClientError),
    DefaultResponse(models::ClientError),
    UnknownValue(serde_json::Value),
}


/// Get the AI agent default config.
pub async fn get_ai_agent_default(configuration: &configuration::Configuration, params: GetAiAgentDefaultParams) -> Result<models::AiAgent, Error<GetAiAgentDefaultError>> {

    let uri_str = format!("{}/ai_agent_default", configuration.base_path);
    let mut req_builder = configuration.client.request(reqwest::Method::GET, &uri_str);

    req_builder = req_builder.query(&[("mode", &params.mode.to_string())]);
    if let Some(ref param_value) = params.language {
        req_builder = req_builder.query(&[("language", &param_value.to_string())]);
    }
    if let Some(ref param_value) = params.model {
        req_builder = req_builder.query(&[("model", &param_value.to_string())]);
    }
    if let Some(ref user_agent) = configuration.user_agent {
        req_builder = req_builder.header(reqwest::header::USER_AGENT, user_agent.clone());
    }
    if let Some(ref token) = configuration.oauth_access_token {
        req_builder = req_builder.bearer_auth(token.to_owned());
    };

    let req = req_builder.build()?;
    let resp = configuration.client.execute(req).await?;

    let status = resp.status();
    let content_type = resp
        .headers()
        .get("content-type")
        .and_then(|v| v.to_str().ok())
        .unwrap_or("application/octet-stream");
    let content_type = super::ContentType::from(content_type);

    if !status.is_client_error() && !status.is_server_error() {
        let content = resp.text().await?;
        match content_type {
            ContentType::Json => serde_json::from_str(&content).map_err(Error::from),
            ContentType::Text => return Err(Error::from(serde_json::Error::custom("Received `text/plain` content type response that cannot be converted to `models::AiAgent`"))),
            ContentType::Unsupported(unknown_type) => return Err(Error::from(serde_json::Error::custom(format!("Received `{unknown_type}` content type response that cannot be converted to `models::AiAgent`")))),
        }
    } else {
        let content = resp.text().await?;
        let entity: Option<GetAiAgentDefaultError> = serde_json::from_str(&content).ok();
        Err(Error::ResponseError(ResponseContent { status, content, entity }))
    }
}

/// Sends an AI request to supported LLMs and returns an answer specifically focused on the user's question given the provided context.
pub async fn post_ai_ask(configuration: &configuration::Configuration, params: PostAiAskParams) -> Result<models::AiResponseFull, Error<PostAiAskError>> {

    let uri_str = format!("{}/ai/ask", configuration.base_path);
    let mut req_builder = configuration.client.request(reqwest::Method::POST, &uri_str);

    if let Some(ref user_agent) = configuration.user_agent {
        req_builder = req_builder.header(reqwest::header::USER_AGENT, user_agent.clone());
    }
    if let Some(ref token) = configuration.oauth_access_token {
        req_builder = req_builder.bearer_auth(token.to_owned());
    };
    req_builder = req_builder.json(&params.ai_ask);

    let req = req_builder.build()?;
    let resp = configuration.client.execute(req).await?;

    let status = resp.status();
    let content_type = resp
        .headers()
        .get("content-type")
        .and_then(|v| v.to_str().ok())
        .unwrap_or("application/octet-stream");
    let content_type = super::ContentType::from(content_type);

    if !status.is_client_error() && !status.is_server_error() {
        let content = resp.text().await?;
        match content_type {
            ContentType::Json => serde_json::from_str(&content).map_err(Error::from),
            ContentType::Text => return Err(Error::from(serde_json::Error::custom("Received `text/plain` content type response that cannot be converted to `models::AiResponseFull`"))),
            ContentType::Unsupported(unknown_type) => return Err(Error::from(serde_json::Error::custom(format!("Received `{unknown_type}` content type response that cannot be converted to `models::AiResponseFull`")))),
        }
    } else {
        let content = resp.text().await?;
        let entity: Option<PostAiAskError> = serde_json::from_str(&content).ok();
        Err(Error::ResponseError(ResponseContent { status, content, entity }))
    }
}

/// Sends an AI request to supported Large Language Models (LLMs) and extracts metadata in form of key-value pairs. In this request, both the prompt and the output can be freeform. Metadata template setup before sending the request is not required.
pub async fn post_ai_extract(configuration: &configuration::Configuration, params: PostAiExtractParams) -> Result<models::AiResponse, Error<PostAiExtractError>> {

    let uri_str = format!("{}/ai/extract", configuration.base_path);
    let mut req_builder = configuration.client.request(reqwest::Method::POST, &uri_str);

    if let Some(ref user_agent) = configuration.user_agent {
        req_builder = req_builder.header(reqwest::header::USER_AGENT, user_agent.clone());
    }
    if let Some(ref token) = configuration.oauth_access_token {
        req_builder = req_builder.bearer_auth(token.to_owned());
    };
    req_builder = req_builder.json(&params.ai_extract);

    let req = req_builder.build()?;
    let resp = configuration.client.execute(req).await?;

    let status = resp.status();
    let content_type = resp
        .headers()
        .get("content-type")
        .and_then(|v| v.to_str().ok())
        .unwrap_or("application/octet-stream");
    let content_type = super::ContentType::from(content_type);

    if !status.is_client_error() && !status.is_server_error() {
        let content = resp.text().await?;
        match content_type {
            ContentType::Json => serde_json::from_str(&content).map_err(Error::from),
            ContentType::Text => return Err(Error::from(serde_json::Error::custom("Received `text/plain` content type response that cannot be converted to `models::AiResponse`"))),
            ContentType::Unsupported(unknown_type) => return Err(Error::from(serde_json::Error::custom(format!("Received `{unknown_type}` content type response that cannot be converted to `models::AiResponse`")))),
        }
    } else {
        let content = resp.text().await?;
        let entity: Option<PostAiExtractError> = serde_json::from_str(&content).ok();
        Err(Error::ResponseError(ResponseContent { status, content, entity }))
    }
}

/// Sends an AI request to supported Large Language Models (LLMs) and returns extracted metadata as a set of key-value pairs.  To define the extraction structure, provide either a metadata template or a list of fields. To learn more about creating templates, see [Creating metadata templates in the Admin Console](https://support.box.com/hc/en-us/articles/360044194033-Customizing-Metadata-Templates) or use the [metadata template API](g://metadata/templates/create).   This endpoint also supports [Enhanced Extract Agent](g://box-ai/ai-tutorials/extract-metadata-structured/#enhanced-extract-agent).  For information about supported file formats and languages, see the [Extract metadata from file (structured)](g://box-ai/ai-tutorials/extract-metadata-structured) API guide.
pub async fn post_ai_extract_structured(configuration: &configuration::Configuration, params: PostAiExtractStructuredParams) -> Result<models::AiExtractStructuredResponse, Error<PostAiExtractStructuredError>> {

    let uri_str = format!("{}/ai/extract_structured", configuration.base_path);
    let mut req_builder = configuration.client.request(reqwest::Method::POST, &uri_str);

    if let Some(ref user_agent) = configuration.user_agent {
        req_builder = req_builder.header(reqwest::header::USER_AGENT, user_agent.clone());
    }
    if let Some(ref token) = configuration.oauth_access_token {
        req_builder = req_builder.bearer_auth(token.to_owned());
    };
    req_builder = req_builder.json(&params.ai_extract_structured);

    let req = req_builder.build()?;
    let resp = configuration.client.execute(req).await?;

    let status = resp.status();
    let content_type = resp
        .headers()
        .get("content-type")
        .and_then(|v| v.to_str().ok())
        .unwrap_or("application/octet-stream");
    let content_type = super::ContentType::from(content_type);

    if !status.is_client_error() && !status.is_server_error() {
        let content = resp.text().await?;
        match content_type {
            ContentType::Json => serde_json::from_str(&content).map_err(Error::from),
            ContentType::Text => return Err(Error::from(serde_json::Error::custom("Received `text/plain` content type response that cannot be converted to `models::AiExtractStructuredResponse`"))),
            ContentType::Unsupported(unknown_type) => return Err(Error::from(serde_json::Error::custom(format!("Received `{unknown_type}` content type response that cannot be converted to `models::AiExtractStructuredResponse`")))),
        }
    } else {
        let content = resp.text().await?;
        let entity: Option<PostAiExtractStructuredError> = serde_json::from_str(&content).ok();
        Err(Error::ResponseError(ResponseContent { status, content, entity }))
    }
}

/// Sends an AI request to supported Large Language Models (LLMs) and returns generated text based on the provided prompt.
pub async fn post_ai_text_gen(configuration: &configuration::Configuration, params: PostAiTextGenParams) -> Result<models::AiResponse, Error<PostAiTextGenError>> {

    let uri_str = format!("{}/ai/text_gen", configuration.base_path);
    let mut req_builder = configuration.client.request(reqwest::Method::POST, &uri_str);

    if let Some(ref user_agent) = configuration.user_agent {
        req_builder = req_builder.header(reqwest::header::USER_AGENT, user_agent.clone());
    }
    if let Some(ref token) = configuration.oauth_access_token {
        req_builder = req_builder.bearer_auth(token.to_owned());
    };
    req_builder = req_builder.json(&params.ai_text_gen);

    let req = req_builder.build()?;
    let resp = configuration.client.execute(req).await?;

    let status = resp.status();
    let content_type = resp
        .headers()
        .get("content-type")
        .and_then(|v| v.to_str().ok())
        .unwrap_or("application/octet-stream");
    let content_type = super::ContentType::from(content_type);

    if !status.is_client_error() && !status.is_server_error() {
        let content = resp.text().await?;
        match content_type {
            ContentType::Json => serde_json::from_str(&content).map_err(Error::from),
            ContentType::Text => return Err(Error::from(serde_json::Error::custom("Received `text/plain` content type response that cannot be converted to `models::AiResponse`"))),
            ContentType::Unsupported(unknown_type) => return Err(Error::from(serde_json::Error::custom(format!("Received `{unknown_type}` content type response that cannot be converted to `models::AiResponse`")))),
        }
    } else {
        let content = resp.text().await?;
        let entity: Option<PostAiTextGenError> = serde_json::from_str(&content).ok();
        Err(Error::ResponseError(ResponseContent { status, content, entity }))
    }
}

